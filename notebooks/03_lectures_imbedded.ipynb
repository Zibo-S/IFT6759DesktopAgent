{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from pathlib import Path\n",
    "\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where the DB is stored locally:\n",
    "\n",
    "When Embedded Weaviate starts for the first time, it creates a permanent datastore in the location set in your persistence_data_path. When your client exits, the Embedded Weaviate instance also exits, but the data persists . The next time the client runs, it starts a new instance of Embedded Weaviate. New Embedded Weaviate instances use the data that is saved in the datastore.\n",
    "\n",
    "## Data storage directory\n",
    "\n",
    "If XDG_DATA_HOME is set, the default is: XDG_DATA_HOME/weaviate/\n",
    "\n",
    "If XDG_DATA_HOME is not set, the default is: ~/.local/share/weaviate\n",
    "\n",
    "In my case the data is stored in the following location: /Users/username/.local/share/weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceciliaacosta/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/warnings.py:158: DeprecationWarning: Dep016: You are using the Weaviate v3 client, which is deprecated.\n",
      "            Consider upgrading to the new and improved v4 client instead!\n",
      "            See here for usage: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/ceciliaacosta/.cache/weaviate-embedded: process ID 22363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-11T20:30:05-04:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-11T20:30:05-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-11T20:30:05-04:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-03-11T20:30:05-04:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-03-11T20:30:05-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-03-11T20:30:05-04:00\"}\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(\n",
    "        additional_env_vars={\"X-HuggingFace-Api-Key\": \"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\"}\n",
    "    )\n",
    ")\n",
    "assert client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the structure of the data vector dabase: We called it PDF_Document. This is the \"Class\" that we are going to use to store the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard pdf_document_3NfwLQdVYPoI in 5.849246ms\",\"time\":\"2024-03-11T20:31:14-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-03-11T20:31:14-04:00\",\"took\":109174}\n"
     ]
    }
   ],
   "source": [
    "client.schema.delete_all()\n",
    "# Create a new class with a vectorizer\n",
    "schema = {\n",
    "    \"class\": \"PDF_Document\",    \n",
    "    \"vectorizer\": \"text2vec-huggingface\",\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"content\",  #What we want to vectorize\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Content of PDF\",\n",
    "            \"moduleConfig\": {\n",
    "                \"text2vec-huggingface\": {\"skip\": False, \"vectorizePropertyName\": False}\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"filename\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"PDF filename\"\n",
    "        },\n",
    "    ],\n",
    "    \"moduleConfig\": {\n",
    "    \"text2vec-huggingface\": {\n",
    "      \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",  # Can be any public or private Hugging Face model.\n",
    "      \"options\": {\n",
    "        \"waitForModel\": True,  # Try this if you get a \"model not ready\" error\n",
    "      }\n",
    "}\n",
    "}\n",
    "}\n",
    "\n",
    "client.schema.create_class(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.documents.elements import DataSourceMetadata\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from weaviate.util import generate_uuid5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(elements, chunk_under_n_chars=500, chunk_new_after_n_chars=1500):\n",
    "\n",
    "    chunks = chunk_by_title(\n",
    "        elements,\n",
    "        multipage_sections=False, # If True, the title of the first page is used for all pages\n",
    "        combine_text_under_n_chars=chunk_under_n_chars,\n",
    "        new_after_n_chars=chunk_new_after_n_chars\n",
    " \n",
    "    )\n",
    "\n",
    "    for i in range(len(chunks)):\n",
    "        chunks[i] = {\"text\": chunks[i].text, \"filename\": chunks[i].metadata.filename}\n",
    "\n",
    "    chunk_texts = [x['text'] for x in chunks]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def add_data_to_weaviate(files, client, chunk_under_n_chars=500, chunk_new_after_n_chars=1500):\n",
    "    for filename in files:\n",
    "        try:\n",
    "            elements = partition_pdf(filename=filename)\n",
    "            chunks = get_chunks(elements, chunk_under_n_chars, chunk_new_after_n_chars)\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        print(f\"Uploading {len(chunks)} chunks for {str(filename)}.\")\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            try:\n",
    "                client.data_object.create(class_name=\"Test\", data_object={\"content\": chunk['text'], \"filename\": filename})\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"Failed to upload chunk {i} for {str(filename)}.\")\n",
    "\n",
    "        with client.batch as batch:\n",
    "            for data_object in chunks:\n",
    "                batch.add_data_object(data_object={\"content\": chunk['text'], \"filename\": filename}, class_name=\"Test\", uuid=generate_uuid5(data_object))\n",
    "\n",
    "        \n",
    "    client.batch.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate import Client\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "def configure_batch(client: Client, batch_size: int, batch_target_rate: int):\n",
    "    \"\"\"\n",
    "    Configure the weaviate client's batch so it creates objects at `batch_target_rate`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client : Client\n",
    "        The Weaviate client instance.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    batch_target_rate : int\n",
    "        The batch target rate as # of objects per second.\n",
    "    \"\"\"\n",
    "\n",
    "    def callback(batch_results: dict) -> None:\n",
    "\n",
    "        # you could print batch errors here\n",
    "        time_took_to_create_batch = batch_size * (client.batch.creation_time/client.batch.recommended_num_objects)\n",
    "        time.sleep(\n",
    "            max(batch_size/batch_target_rate - time_took_to_create_batch + 1, 0)\n",
    "        )\n",
    "\n",
    "    client.batch.configure(\n",
    "        batch_size=batch_size,\n",
    "        timeout_retries=5,\n",
    "        callback=callback,\n",
    "    )\n",
    "\n",
    "def add_data_to_weaviate(files, client, chunk_under_n_chars=500, chunk_new_after_n_chars=1500, batch_size=10, batch_target_rate=2):\n",
    "    configure_batch(client, batch_size, batch_target_rate)\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            elements = partition_pdf(filename=filename)\n",
    "            chunks = get_chunks(elements, chunk_under_n_chars, chunk_new_after_n_chars)\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        print(f\"Uploading {len(chunks)} chunks for {str(filename)}.\")\n",
    "        with client.batch as batch:\n",
    "            for chunk in chunks:\n",
    "                data_object = {\"content\": chunk['text'], \"filename\": filename}\n",
    "                batch.add_data_object(data_object=data_object, class_name=\"Test\", uuid=uuid.uuid5(uuid.NAMESPACE_DNS, str(data_object)))\n",
    "\n",
    "    client.batch.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the files to the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 151 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec06.pdf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard test_3hwrBnPnDlie in 4.436345ms\",\"time\":\"2024-03-11T20:33:20-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-03-11T20:33:20-04:00\",\"took\":114777}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 123 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec12.pdf.\n",
      "Uploading 59 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec07.pdf.\n",
      "Uploading 60 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec11.pdf.\n",
      "Uploading 87 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec05.pdf.\n",
      "Uploading 215 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec04.pdf.\n",
      "Uploading 63 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec10.pdf.\n",
      "Uploading 77 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec01.pdf.\n",
      "Uploading 90 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec03.pdf.\n",
      "Uploading 67 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec02.pdf.\n",
      "Uploading 67 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec09.pdf.\n",
      "Uploading 87 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/coursematerial/lec08.pdf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceciliaacosta/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/batch/crud_batch.py:1127: RuntimeWarning: The BatchExecutor was shutdown, most probably when it exited the `with` statement. The BatchExecutor will be reinitialized. If you are not `batch` in `with client.batch as batch`, be sure to shut the BatchExecutor down when your data import finishes: `client.batch.shutdown()`. To restart the BatchExecutor, use `client.batch.start()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_path = '../data/coursematerial'\n",
    "import glob\n",
    "# Dictionary to hold file names and their elements\n",
    "\n",
    "# Find all PDF files in the specified directory\n",
    "pdf_files = glob.glob(os.path.join(directory_path, '*.pdf'))\n",
    "add_data_to_weaviate(\n",
    "    files=pdf_files,\n",
    "    client=client,\n",
    "    chunk_under_n_chars=250,\n",
    "    chunk_new_after_n_chars=500,\n",
    "    batch_size=10,\n",
    "    batch_target_rate=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cells below are two examples of queries to the database to get the data you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceciliaacosta/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/warnings.py:158: DeprecationWarning: Dep016: You are using the Weaviate v3 client, which is deprecated.\n",
      "            Consider upgrading to the new and improved v4 client instead!\n",
      "            See here for usage: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Get': {'Test': [{'content': 'Why this class?\\n\\n2017 Kaggle survey of data science and ML practitioners: what data science methods do you use at work?\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n32 / 65\\n\\nML Workﬂow\\n\\nML workﬂow sketch:\\n\\n1 Should I use ML on this problem?\\n\\nIs there a pattern to detect? Can I solve it analytically? Do I have data? 2 Gather and organize data.\\n\\nPreprocessing, cleaning, visualizing.\\n\\n3 Establishing a baseline, i.e., implement the simplest, default ML', 'filename': '../data/course_test/lec01.pdf'}, {'content': 'Typically,wewillseeinlaterchaptersthattheestimationerrorisoftendecomposedas,forθ!aminimizeronΘoftheexpectedriskR(fθ!):!R(fˆθ)−R(fθ!)\"=!R(fˆθ)−ˆR(fˆθ)\"+!ˆR(fˆθ)−ˆR(fθ!)\"+!ˆR(fθ!)−R(fθ!)\"!2supθ∈Θ###ˆR(fθ)−R(fθ)###+empiricaloptimizationerror.Theuniformdeviationgrowswiththe“size”ofΘ,andusuallydecayswithn.SeemoredetailsinChapter4.Capacitycontrol.Inordertoavoidoverﬁtting,weneedtomakesurethatthesetofallowedfunctionsisnottoolarge,bytypicallyreducingthenumberofparameters,orbyrestrictingthenormofpredictor', 'filename': '../data/course_test/lec02.pdf'}, {'content': '“size”ofΘErrorstesttrainoverﬁtting\\n\\n26CHAPTER2.INTRODUCTIONTOSUPERVISEDLEARNING\\n\\nSource: Francis Bach. Learning Theory from First Principles.\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n51 / 60\\n\\nifte0,0XEOI1,1Dte0,0XEOI1,1ite0,0\\n\\n2D Example\\n\\nx is uniform on the ellipses.\\n\\nt depends on which ellipse x falls in\\n\\n, ∈ {•\\n\\n}\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n52 / 60', 'filename': '../data/course_test/lec02.pdf'}, {'content': 'Why not R?\\n\\nI don’t know R. The machine learning community mostly uses Python. Follow-up courses like STA414 typically use Python.\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n6 / 65\\n\\nCourse Information\\n\\nMost information: website is main source of information; check regularly!', 'filename': '../data/course_test/lec01.pdf'}, {'content': 'Quantifying Uncertainty\\n\\nThe entropy of a discrete random variable is a number that quantiﬁes the uncertainty inherent in its possible outcomes.\\n\\nThe mathematical deﬁnition of entropy that we give in a few slides may seem arbitrary, but it can be motivated axiomatically.\\n\\n(cid:73) If you’re interested, check: Information Theory by Robert Ash.\\n\\nTo explain entropy, consider ﬂipping two diﬀerent coins...\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n17 / 60', 'filename': '../data/course_test/lec02.pdf'}, {'content': 'Choosing a Good Split\\n\\nConsider the following data. Let’s split on width.\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n13 / 60\\n\\nChoosing a Good Split\\n\\nRecall: classify by majority.\\n\\nA and B have the same misclassiﬁcation rate, so which is the best split? Vote!\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n14 / 60', 'filename': '../data/course_test/lec02.pdf'}, {'content': 'In other words, STA314 takes a more statistical perspective than CSC311 while covering the same core of material.\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n15 / 65\\n\\nAdvanced Courses\\n\\nThis course will help prepare you for the following courses.\\n\\nSTA414 (Statistical Methods for Machine Learning II)\\n\\nThis course is the follow-up course, which delves deeper into the probabilistic interpretation of machine learning that we cover in the last few weeks.', 'filename': '../data/course_test/lec01.pdf'}, {'content': 'Regression tree:\\n\\n(cid:73) continuous output (cid:73) leaf value y m typically set to the mean value in\\n\\nt (m1), . . . , t (mk ) {\\n\\nIntro ML (UofT)\\n\\nSTA314-Lec1\\n\\n}\\n\\n10 / 60', 'filename': '../data/course_test/lec02.pdf'}, {'content': 'Pitfalls: Normalization\\n\\nNearest neighbors can be sensitive to the ranges of diﬀerent features.\\n\\nOften, the units are arbitrary:\\n\\nSimple ﬁx: normalize each dimension to be zero mean and unit variance. I.e., compute the mean µj and standard deviation σj , and take\\n\\n˜x (i) j =', 'filename': '../data/course_test/lec01.pdf'}, {'content': 'x]\\n\\n(cid:125)\\n\\n+ Var[t\\n\\n|\\n\\nx]\\n\\n\\uf8f9\\n\\nBayes error\\n\\n(cid:124)\\n\\n(cid:123)(cid:122)\\n\\n(cid:125)\\n\\n\\uf8fa \\uf8fb\\n\\n17 / 29\\n\\n382.OverviewofSupervisedLearning', 'filename': '../data/course_test/lec03.pdf'}]}}}\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.Client(\"http://localhost:8079\")\n",
    "# Perform a query\n",
    "query1 = \"\"\"\n",
    "{\n",
    "  Get {\n",
    "    PDF_Document (limit: 10) {\n",
    "      content\n",
    "      filename\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "result = client.query.raw(query1)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Aggregate': {'Test': [{'meta': {'count': 206}}]}}}\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "{\n",
    "  Aggregate {\n",
    "    PDF_Document {\n",
    "      meta {\n",
    "        count\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = client.query.raw(query2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift-6758",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
