{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from pathlib import Path\n",
    "\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ceciliaacosta/miniconda3/envs/ift-6758/lib/python3.11/site-packages/weaviate/warnings.py:158: DeprecationWarning: Dep016: You are using the Weaviate v3 client, which is deprecated.\n",
      "            Consider upgrading to the new and improved v4 client instead!\n",
      "            See here for usage: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Shutting down... \",\"time\":\"2024-03-10T19:34:53-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Stopped serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-03-10T19:34:53-04:00\"}\n",
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-10T19:34:53-04:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-10T19:34:53-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-10T19:34:53-04:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded weaviate wasn't listening on ports http:8079 & grpc:50060, so starting embedded weaviate again\n",
      "Started /Users/ceciliaacosta/.cache/weaviate-embedded: process ID 15205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-03-10T19:34:53-04:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-03-10T19:34:53-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-03-10T19:34:53-04:00\"}\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(\n",
    "        additional_env_vars={\"X-HuggingFace-Api-Key\": \"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\"}\n",
    "    )\n",
    ")\n",
    "assert client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard test_JjpY07oDo51r in 5.397514ms\",\"time\":\"2024-03-10T19:51:46-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-03-10T19:51:46-04:00\",\"took\":89602}\n"
     ]
    }
   ],
   "source": [
    "client.schema.delete_all()\n",
    "# Create a new class with a vectorizer\n",
    "schema = {\n",
    "    \"class\": \"Test\",    \n",
    "    \"vectorizer\": \"text2vec-huggingface\",\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"content\",  #What we want to vectorize\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Content of PDF\",\n",
    "            \"moduleConfig\": {\n",
    "                \"text2vec-huggingface\": {\"skip\": False, \"vectorizePropertyName\": False}\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"filename\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"PDF filename\"\n",
    "        },\n",
    "    ],\n",
    "    \"moduleConfig\": {\n",
    "    \"text2vec-huggingface\": {\n",
    "      \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",  # Can be any public or private Hugging Face model.\n",
    "      \"options\": {\n",
    "        \"waitForModel\": True,  # Try this if you get a \"model not ready\" error\n",
    "      }\n",
    "}\n",
    "}\n",
    "}\n",
    "\n",
    "client.schema.create_class(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.documents.elements import DataSourceMetadata\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from weaviate.util import generate_uuid5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ratelimit\n",
      "  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ratelimit\n",
      "  Building wheel for ratelimit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5895 sha256=45132d17d2595e061e72aafa45accfe36ce988990adbaed9e4cff91976e2c7a9\n",
      "  Stored in directory: /Users/ceciliaacosta/Library/Caches/pip/wheels/ee/d5/e5/8fbffe089140fb498987b7709becf861086daace105d243475\n",
      "Successfully built ratelimit\n",
      "Installing collected packages: ratelimit\n",
      "Successfully installed ratelimit-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ratelimit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "RATE_LIMIT = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(elements, chunk_under_n_chars=500, chunk_new_after_n_chars=1500):\n",
    "\n",
    "    chunks = chunk_by_title(\n",
    "        elements,\n",
    "        multipage_sections=False, # If True, the title of the first page is used for all pages\n",
    "        combine_text_under_n_chars=chunk_under_n_chars,\n",
    "        new_after_n_chars=chunk_new_after_n_chars\n",
    " \n",
    "    )\n",
    "\n",
    "    for i in range(len(chunks)):\n",
    "        chunks[i] = {\"text\": chunks[i].text, \"filename\": chunks[i].metadata.filename}\n",
    "\n",
    "    chunk_texts = [x['text'] for x in chunks]\n",
    "    return chunks\n",
    "\n",
    "#@sleep_and_retry\n",
    "#@limits(calls=RATE_LIMIT, period=1)\n",
    "def add_data_to_weaviate(files, client, chunk_under_n_chars=500, chunk_new_after_n_chars=1500):\n",
    "    for filename in files:\n",
    "        try:\n",
    "            elements = partition_pdf(filename=filename)\n",
    "            chunks = get_chunks(elements, chunk_under_n_chars, chunk_new_after_n_chars)\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        print(f\"Uploading {len(chunks)} chunks for {str(filename)}.\")\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            try:\n",
    "                client.data_object.create(class_name=\"Test\", data_object={\"content\": chunk['text'], \"filename\": filename})\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"Failed to upload chunk {i} for {str(filename)}.\")\n",
    "\n",
    "        with client.batch as batch:\n",
    "            for data_object in chunks:\n",
    "                batch.add_data_object(data_object={\"content\": chunk['text'], \"filename\": filename}, class_name=\"Test\", uuid=generate_uuid5(data_object))\n",
    "\n",
    "        \n",
    "    client.batch.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate import Client\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "def configure_batch(client: Client, batch_size: int, batch_target_rate: int):\n",
    "    \"\"\"\n",
    "    Configure the weaviate client's batch so it creates objects at `batch_target_rate`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client : Client\n",
    "        The Weaviate client instance.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    batch_target_rate : int\n",
    "        The batch target rate as # of objects per second.\n",
    "    \"\"\"\n",
    "\n",
    "    def callback(batch_results: dict) -> None:\n",
    "\n",
    "        # you could print batch errors here\n",
    "        time_took_to_create_batch = batch_size * (client.batch.creation_time/client.batch.recommended_num_objects)\n",
    "        time.sleep(\n",
    "            max(batch_size/batch_target_rate - time_took_to_create_batch + 1, 0)\n",
    "        )\n",
    "\n",
    "    client.batch.configure(\n",
    "        batch_size=batch_size,\n",
    "        timeout_retries=5,\n",
    "        callback=callback,\n",
    "    )\n",
    "\n",
    "def add_data_to_weaviate(files, client, chunk_under_n_chars=500, chunk_new_after_n_chars=1500, batch_size=10, batch_target_rate=2):\n",
    "    configure_batch(client, batch_size, batch_target_rate)\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            elements = partition_pdf(filename=filename)\n",
    "            chunks = get_chunks(elements, chunk_under_n_chars, chunk_new_after_n_chars)\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        print(f\"Uploading {len(chunks)} chunks for {str(filename)}.\")\n",
    "        with client.batch as batch:\n",
    "            for chunk in chunks:\n",
    "                data_object = {\"content\": chunk['text'], \"filename\": filename}\n",
    "                batch.add_data_object(data_object=data_object, class_name=\"Test\", uuid=uuid.uuid5(uuid.NAMESPACE_DNS, str(data_object)))\n",
    "\n",
    "    client.batch.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 77 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/course_test/lec01.pdf.\n",
      "Uploading 90 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/course_test/lec03.pdf.\n",
      "Uploading 67 chunks for /Users/ceciliaacosta/Project_IFT/IFT6759DesktopAgent/data/course_test/lec02.pdf.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_path = 'data/course_test'\n",
    "import glob\n",
    "# Dictionary to hold file names and their elements\n",
    "\n",
    "# Find all PDF files in the specified directory\n",
    "pdf_files = glob.glob(os.path.join(directory_path, '*.pdf'))\n",
    "add_data_to_weaviate(\n",
    "    files=pdf_files,\n",
    "    client=client,\n",
    "    chunk_under_n_chars=250,\n",
    "    chunk_new_after_n_chars=500,\n",
    "    batch_size=10,\n",
    "    batch_target_rate=2\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift-6758",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
